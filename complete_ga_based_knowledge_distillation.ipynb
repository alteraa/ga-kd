{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "import os\n",
    "import csv\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import typing as t\n",
    "from sentence_transformers import util\n",
    "from contextlib import contextmanager\n",
    "\n",
    "ALLNLI_DATASET_URL = \"https://sbert.net/datasets/AllNLI.tsv.gz\"\n",
    "STS_BENCHMARK_DATASET_URL = \"https://sbert.net/datasets/stsbenchmark.tsv.gz\"\n",
    "\n",
    "\n",
    "def download_dataset(url: str, download_path: str) -> None:\n",
    "    \"\"\"Download dataset from given url to download_path.\n",
    "\n",
    "    Args:\n",
    "        url (str): Dataset URL.\n",
    "        download_path (str): Path to download.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(download_path):\n",
    "        util.http_get(url, download_path)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def open_dataset(dataset_path: str) -> t.Generator[csv.DictReader, None, None]:\n",
    "    \"\"\"Open dataset within a context manager.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to dataset file.\n",
    "\n",
    "    Yields:\n",
    "        Iterator[t.Generator[csv.DictReader, None, None]]: CSV reader.\n",
    "    \"\"\"\n",
    "    file = gzip.open(dataset_path, \"rt\", encoding=\"utf8\")\n",
    "    reader = csv.DictReader(file, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    yield reader\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def read_as_dataframe(dataset_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read from given dataset path as DataFrame.\"\"\"\n",
    "    with open_dataset(dataset_path) as reader:\n",
    "        columns = reader.fieldnames\n",
    "        lines = [[row[field] for field in columns] for row in reader]\n",
    "        return pd.DataFrame(lines, columns=columns)\n",
    "\n",
    "\n",
    "# genetics\n",
    "import math\n",
    "import typing as t\n",
    "from random import Random\n",
    "from copy import deepcopy\n",
    "\n",
    "random_state = Random(42)\n",
    "\n",
    "\n",
    "class Gene:\n",
    "    @property\n",
    "    def value(self) -> int:\n",
    "        \"\"\"Current value of the gene.\"\"\"\n",
    "        return self._value\n",
    "\n",
    "    @property\n",
    "    def value_range(self) -> t.Tuple[int, int]:\n",
    "        \"\"\"Value range for the range.\"\"\"\n",
    "        return self._value_range\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        value_range: t.Tuple[int, int],\n",
    "        initial_value: t.Optional[int] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Gene base class.\n",
    "\n",
    "        Args:\n",
    "            value_range (t.Tuple[int, int]): Value range in `[min, max)` order.\n",
    "            initial_value (t.Optional[int], optional): Initial value. If None, then init with a random value. Defaults to None.\n",
    "        \"\"\"\n",
    "        assert value_range[0] < value_range[1]\n",
    "        self._value_range = value_range\n",
    "        if initial_value:\n",
    "            a, b = value_range\n",
    "            assert a <= initial_value <= b\n",
    "            self._value = initial_value\n",
    "        else:\n",
    "            self._value = self._rand_value()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.value)\n",
    "\n",
    "    def _rand_value(self) -> int:\n",
    "        \"\"\"Generate random value.\"\"\"\n",
    "        a, b = self._value_range\n",
    "        return random_state.choice(range(a, b))\n",
    "\n",
    "    def randomize(self) -> None:\n",
    "        \"\"\"Randomize current value.\"\"\"\n",
    "        self._value = self._rand_value()\n",
    "\n",
    "\n",
    "class Chromosome:\n",
    "    @property\n",
    "    def fitness(self) -> float:\n",
    "        \"\"\"Current fitness value for the chromosome.\"\"\"\n",
    "        return self._fitness\n",
    "\n",
    "    @property\n",
    "    def genes(self) -> t.List[Gene]:\n",
    "        \"\"\"List of current genes.\"\"\"\n",
    "        return self._genes\n",
    "\n",
    "    @property\n",
    "    def length(self) -> int:\n",
    "        \"\"\"Number of genes.\"\"\"\n",
    "        return self._length\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        length: int,\n",
    "        initial_genes: t.Optional[t.List[Gene]] = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Chromosome base class.\n",
    "\n",
    "        Args:\n",
    "            length (int): Number of genes (ie. chromosome length).\n",
    "            initial_genes (t.Optional[t.List[Gene]], optional): Initial genes. If None, then initialize with random genes. Defaults to None.\n",
    "        \"\"\"\n",
    "        assert length > 0\n",
    "        self._length = length\n",
    "        if not initial_genes:\n",
    "            assert \"value_range\" in kwargs\n",
    "            self._value_range = kwargs[\"value_range\"]\n",
    "            self._genes = self._rand_genes()\n",
    "        else:\n",
    "            self._genes = initial_genes\n",
    "        self._fitness = 0\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self._genes)\n",
    "\n",
    "    def _rand_genes(self) -> t.List[Gene]:\n",
    "        \"\"\"Generate random genes.\"\"\"\n",
    "        return [Gene(self._value_range) for _ in range(self._length)]\n",
    "\n",
    "    def to_list(self) -> t.List[int]:\n",
    "        \"\"\"Convert gene values to list.\"\"\"\n",
    "        return [g.value for g in self._genes]\n",
    "\n",
    "    def apply_fitness_fn(self, fn: t.Callable[[\"Chromosome\"], float]) -> None:\n",
    "        \"\"\"Apply fitness function. After applying, updates its current fitness value.\n",
    "\n",
    "        Args:\n",
    "            fn (t.Callable[[&quot;Chromosome&quot;], float]): Fitness function.\n",
    "        \"\"\"\n",
    "        self._fitness = fn(self)\n",
    "\n",
    "    def mutate(self, rate: float) -> None:\n",
    "        \"\"\"Mutation operator.\n",
    "\n",
    "        Args:\n",
    "            rate (float): Mutation rate in `[0, 1]`.\n",
    "        \"\"\"\n",
    "        for gene in self._genes:\n",
    "            if random_state.random() < rate:\n",
    "                gene.randomize()\n",
    "\n",
    "    def crossover(self, other: \"Chromosome\") -> \"Chromosome\":\n",
    "        \"\"\"Crossover operator.\n",
    "\n",
    "        Args:\n",
    "            other (Chromosome): Other chromosome to crossover.\n",
    "\n",
    "        Returns:\n",
    "            Chromosome: New (child) chromosome.\n",
    "        \"\"\"\n",
    "        child_genes = []\n",
    "        mid_point = random_state.randint(0, self._length)\n",
    "        for i in range(self._length):\n",
    "            if i < mid_point:\n",
    "                child_genes.append(self._genes[i])\n",
    "            else:\n",
    "                child_genes.append(other.genes[i])\n",
    "        return Chromosome(self._length, child_genes)\n",
    "\n",
    "\n",
    "class Population:\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Population size.\"\"\"\n",
    "        return self._size\n",
    "\n",
    "    @property\n",
    "    def global_best(self) -> Chromosome:\n",
    "        \"\"\"Global best chromosome.\"\"\"\n",
    "        return self._global_best\n",
    "\n",
    "    @property\n",
    "    def local_best(self) -> Chromosome:\n",
    "        \"\"\"Local best chromosome (for last evaluation).\"\"\"\n",
    "        return self._local_best\n",
    "\n",
    "    @property\n",
    "    def best_chromosomes(self) -> t.List[Chromosome]:\n",
    "        \"\"\"Best of local bests.\"\"\"\n",
    "        return self._best_chromosomes\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        size: int,\n",
    "        mutation_rate: float,\n",
    "        initial_chromosomes: t.Optional[t.List[Chromosome]] = None,\n",
    "        keep_best_chromosomes: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Population base class.\n",
    "\n",
    "        Args:\n",
    "            size (int): Population size.\n",
    "            mutation_rate (float): Mutation rate in `[0, 1]` range.\n",
    "            initial_chromosomes (t.Optional[t.List[Chromosome]], optional): Initial chromosomes. If None, then init with random chromosomes. Defaults to None.\n",
    "            keep_best_chromosomes (bool): Keep local bests on each evaluation. Defaults to True.\n",
    "        \"\"\"\n",
    "        self._size = size\n",
    "        self._mutation_rate = mutation_rate\n",
    "        if not initial_chromosomes:\n",
    "            assert \"value_range\" in kwargs\n",
    "            assert \"length\" in kwargs\n",
    "            self._value_range = kwargs[\"value_range\"]\n",
    "            self._length = kwargs[\"length\"]\n",
    "            self.chromosomes = self._rand_chromosomes()\n",
    "        else:\n",
    "            self.chromosomes = initial_chromosomes\n",
    "        self._global_best = deepcopy(self.chromosomes[0])\n",
    "        self.keep_best_chromosomes = keep_best_chromosomes\n",
    "        self._best_chromosomes = []\n",
    "\n",
    "    def _rand_chromosomes(self) -> t.List[Chromosome]:\n",
    "        \"\"\"Generate random chromosomes.\"\"\"\n",
    "        return [\n",
    "            Chromosome(self._length, value_range=self._value_range)\n",
    "            for _ in range(self._size)\n",
    "        ]\n",
    "\n",
    "    def eval(self, fitness_fn: t.Callable[[t.List[int]], float]) -> None:\n",
    "        \"\"\"Evaluate all chromosomes with given function.\n",
    "\n",
    "        Args:\n",
    "            fitness_fn (t.Callable[[t.List[int], float]]): Fitness function to evaluate.\n",
    "        \"\"\"\n",
    "        # ? apply fitnes function to all\n",
    "        self._local_best = self.chromosomes[0]\n",
    "        for c in self.chromosomes:\n",
    "            c.apply_fitness_fn(lambda c: fitness_fn(c.to_list()))\n",
    "            if c.fitness > self._local_best.fitness:\n",
    "                self._local_best = c\n",
    "        if self._local_best.fitness > self.global_best.fitness:\n",
    "            self._global_best = deepcopy(self._local_best)\n",
    "        if self.keep_best_chromosomes:\n",
    "            self._best_chromosomes.append(deepcopy(self._local_best))\n",
    "\n",
    "    def update(self) -> None:\n",
    "        \"\"\"Update all chromosomes for its' current states.\"\"\"\n",
    "        # apply natural selection\n",
    "        mating_pool: t.List[Chromosome] = []\n",
    "        for c in self.chromosomes:\n",
    "            n = math.floor((c.fitness / self._local_best.fitness) * 100)\n",
    "            mating_pool.extend([c for _ in range(n)])\n",
    "        # create next generation\n",
    "        pool_size = len(mating_pool) - 1\n",
    "        for i in range(self._size):\n",
    "            c1 = mating_pool[random_state.randint(0, pool_size)]\n",
    "            c2 = mating_pool[random_state.randint(0, pool_size)]\n",
    "            child = c1.crossover(c2)\n",
    "            child.mutate(self._mutation_rate)\n",
    "            self.chromosomes[i] = child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithms based Knowledge Distillation\n",
    "\n",
    "This notebook simply introduces a knowledge distillation application with a pretrained model built on Transformer architecture and uses genetics algorithms to isolate best fitted pretrained layers from base (teacher) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neural network libraries and utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import models, losses, evaluation\n",
    "from sentence_transformers import (\n",
    "    LoggingHandler,\n",
    "    SentenceTransformer,\n",
    "    util,\n",
    "    InputExample,\n",
    ")\n",
    "from sentence_transformers.datasets import ParallelSentencesDataset\n",
    "# import general utils and helper libraries\n",
    "import random\n",
    "import typing as t\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "\n",
    "You can set all related parameters with this project, including genetic hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set utility variables\n",
    "random_state = random.Random(42) # random state to get same result for every run this notebook\n",
    "# set global variables\n",
    "model_name = \"all-MiniLM-L12-v2\" # module to be distilled (ie. teacher model)\n",
    "output_path = f\"output/{model_name}_\" + datetime.now().strftime(r\"%Y-%m-%d_%H-%M-%S\") # output path to save model file and evaluation results\n",
    "max_train_samples = 1_000 # maximum number of training samples\n",
    "train_batch_size = 32 # batch size for training\n",
    "inference_batch_size = 32 # batch size for trained model\n",
    "max_sentence_length = 256 # maximum char length for each sample (sentence) in the training set\n",
    "### standard neural network hyperparameters ###\n",
    "epochs = 1 \n",
    "warmup_steps = 1000\n",
    "evaluation_steps = 5000\n",
    "learning_rate = 1e-4\n",
    "epsilon = 1e-6\n",
    "### standard neural network hyperparameters ###\n",
    "# set hyperparameters for genetic algorithms\n",
    "max_generation = 10 # maximum number of generations (ie. max iteration)\n",
    "population_size = 10 # population size (ie. number of chromosome for each generation)\n",
    "mutation_rate = 0.01 # mutation rate (%)\n",
    "chromosome_length = 10 # number of layers (because each gene represents a layer's indice)\n",
    "gene_value_range = (0, 12)  # value range for a gene => [a, b) means a is included while b is excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load teacher model\n",
    "\n",
    "Teacher model is the base model to be distilled. We will select its encoder layers within genetics processes to train best distilled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We will download the training and eval (ie. benchmark) datasets seperately and convert them to DataFrame.\n",
    "We are using these datasets:\n",
    "- For training: [**ALLNLI**](https://www.sbert.net/examples/datasets/README.html): Includes [SNLI](https://nlp.stanford.edu/projects/snli/) and [MultiNLI](https://www.nyu.edu/projects/bowman/multinli/) datsets\n",
    "- For benchmark: [**STS Benchmark**](http://ixa2.si.ehu.eus/stswiki/index.php/Main_Page): STS Benchmark comprises a selection of the English datasets used in the STS tasks organized in the context of SemEval between 2012 and 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_as_dataframe(url: str, download_path: str):\n",
    "    download_dataset(url, download_path)\n",
    "    return read_as_dataframe(download_path)\n",
    "\n",
    "\n",
    "# download training dataset (ALLNLI)\n",
    "training_ds = download_as_dataframe(\n",
    "    ALLNLI_DATASET_URL,\n",
    "    \"datasets/allnli.tsv.gz\",\n",
    ")\n",
    "# download evaluation (ie. benchmark) dataset (STSBENCHMARK)\n",
    "benchmark_ds = download_as_dataframe(\n",
    "    STS_BENCHMARK_DATASET_URL,\n",
    "    \"datasets/stsbenchmark.tsv.gz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and benchmark evaluators\n",
    "\n",
    "Evaluators are proper objects to pass through fit function of teacher models. It includes the dataset and eval functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training evaluator\n",
    "train_sents = training_ds[training_ds[\"split\"] == \"train\"].loc[\n",
    "    :, [\"sentence1\", \"sentence2\"]\n",
    "]\n",
    "X_train = list(\n",
    "    set(train_sents[\"sentence1\"].to_list() + train_sents[\"sentence2\"].to_list())\n",
    ")\n",
    "random_state.shuffle(X_train)\n",
    "X_train = X_train[:max_train_samples]  # limit train dataset\n",
    "train_eval = evaluation.MSEEvaluator(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    teacher_model,\n",
    "    name=\"allnli-train\",\n",
    ")\n",
    "\n",
    "# benchmark evaluator\n",
    "bench_sents = benchmark_ds[benchmark_ds[\"split\"] == \"dev\"].loc[\n",
    "    :, [\"sentence1\", \"sentence2\", \"score\"]\n",
    "]\n",
    "bench_samples = [\n",
    "    InputExample(\n",
    "        texts=[bench_sents.iloc[i, 0], bench_sents.iloc[i, 1]],\n",
    "        label=(float(bench_sents.iloc[i, 2]) / 5.0),\n",
    "    )\n",
    "    for i in range(len(bench_sents))\n",
    "]\n",
    "bench_eval = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    bench_samples,\n",
    "    name=\"sts-dev\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate teacher model\n",
    "\n",
    "We first evaluate the teacher model on benchmark dataaset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_eval_result = bench_eval(teacher_model)\n",
    "print(\"Teacher model's benchmark result:\", teacher_eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define fitness function\n",
    "\n",
    "We define fitness function to pass genetics algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_model_from_layers(layers: t.List[int]) -> SentenceTransformer:\n",
    "    \"\"\"Create a student model same as teacher model with given layers indices.\n",
    "\n",
    "    Args:\n",
    "        layers (t.List[int]): List of layer indices.\n",
    "\n",
    "    Returns:\n",
    "        SentenceTransformer: Student model.\n",
    "    \"\"\"\n",
    "    student_model = SentenceTransformer(model_name)\n",
    "    auto_model = student_model._first_module().auto_model\n",
    "    new_layers = torch.nn.ModuleList(\n",
    "        [\n",
    "            layer_module\n",
    "            for i, layer_module in enumerate(auto_model.encoder.layer)\n",
    "            if i in layers\n",
    "        ]\n",
    "    )\n",
    "    auto_model.encoder.layer = new_layers\n",
    "    auto_model.config.num_hidden_layers = len(layers)\n",
    "    return student_model\n",
    "\n",
    "\n",
    "def fitness_function(layers: t.List[int]) -> float:\n",
    "    \"\"\"Fitness (or object) function. \n",
    "\n",
    "    Args:\n",
    "        layers (t.List[int]): List of layer indices.\n",
    "\n",
    "    Returns:\n",
    "        float: Benchmark eval result (rated with teacher model's result).\n",
    "    \"\"\"\n",
    "    student_model = get_student_model_from_layers(layers)\n",
    "    train_data = ParallelSentencesDataset(\n",
    "        student_model=student_model,\n",
    "        teacher_model=teacher_model,\n",
    "        batch_size=inference_batch_size,\n",
    "        use_embedding_cache=False,\n",
    "    )\n",
    "    train_data.add_dataset(\n",
    "        [[sent] for sent in X_train],\n",
    "        max_sentence_length=max_sentence_length,\n",
    "    )\n",
    "    train_dataloader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
    "    train_loss = losses.MSELoss(model=student_model)\n",
    "\n",
    "    student_model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        evaluator=evaluation.SequentialEvaluator([bench_eval, train_eval]),\n",
    "        epochs=epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        evaluation_steps=evaluation_steps,\n",
    "        output_path=output_path,\n",
    "        optimizer_params={\"lr\": learning_rate, \"eps\": epsilon},\n",
    "        save_best_model=False,\n",
    "        use_amp=True,\n",
    "    )\n",
    "    return bench_eval(student_model) / teacher_eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run genetic algorithms\n",
    "\n",
    "Finally, we run the genetics processes to get best suited teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = Population(\n",
    "    population_size,\n",
    "    mutation_rate,\n",
    "    value_range=gene_value_range,\n",
    "    length=chromosome_length,\n",
    "    keep_best_chromosomes=True,\n",
    ")\n",
    "\n",
    "for i in range(max_generation):\n",
    "    population.eval(fitness_function)\n",
    "    population.update()\n",
    "    print(population.local_best, population.local_best.fitness)\n",
    "print(population.global_best, population.global_best.fitness)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
